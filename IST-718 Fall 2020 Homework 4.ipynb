{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.6.11",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "name": "IST-718 Fall 2020 Homework 4",
    "notebookId": 3053731002708017,
    "colab": {
      "name": "IST-718 Fall 2020 Homework 4.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baschram/bda-718-group-1/blob/master/IST-718%20Fall%202020%20Homework%204.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKpA0wTiDF5T"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8kAictDF5T"
      },
      "source": [
        "# IST 718: Big Data Analytics\n",
        "\n",
        "- Professor: Willard Williamson <wewillia@syr.edu>\n",
        "- Faculty Assistant: Vidushi Mishra <vmishr01@syr.edu>\n",
        "- Faculty Assistant: Pranav Kottoli Radhakrishna <pkottoli@syr.edu>\n",
        "## General instructions:\n",
        "\n",
        "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
        "- There could be tests in some cells (i.e., `assert` and `np.testing.` statements). These tests (if present) are used to grade your answers. **However, the professor and FAs could use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
        "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
        "`Kernel`$\\rightarrow$`Restart and Run All`.  All runtime errors will result in a minimum penalty of half off.\n",
        "- Data Bricks is the official class runtime environment so you should test your code on Data Bricks before submission.  If there is a runtime problem in the grading environment, we will try your code on Data Bricks before making a final grading decision.\n",
        "- All plots shall include descriptinve title and axis labels.  Plot legends shall be included where possible.  Unless stated otherwise, plots can be made using any Python plotting package.  It is understood that spark data structures must be converted to something like numpy or pandas prior to making plots.  All required mathematical operations, filtering, selection, etc., required by a homework question shall be performed in spark prior to converting to numpy or pandas.\n",
        "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
        "- Don't add or remove files from your git repo.\n",
        "- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n",
        "- You are free to add additional code cells around the cells marked `your code here`.\n",
        "- We reserve the right to take points off for operations that are extremely inefficient or \"heavy weight\".  This is a big data class and extremely inefficient operations make a big difference when scaling up to large data sets.  For example, the spark dataframe collect() method is a very heavy weight operation and should not be used unless it there is a real need for it.  An example where collect() might be needed is to get ready to make a plot after filtering a spark dataframe.\n",
        "- import * is not allowed because it is considered a very bad coding practice and in some cases can result in a significant delay (which slows down the grading process) in loading imports.  For example, the statement `from sympy import *` is not allowed.  You must import the specific packages that you need.\n",
        "- If you perform databricks specific operations, you MUST protect those operations in an if statement by calling the is_databricks() function provided in all homework assignments.  For example, if you use dbutils (databricks utilities), only run dbutils commands if is_databricks() returns true.  Runtime errors created in the grading environment by not protecting databricks specific commands in an if statement will result in a runtime error points deduction. \n",
        "- The graders reserve the right to deduct points for subjective things we see with your code.  For example, if we ask you to create a pandas data frame to display values from an investigation and you hard code the values, we will take points off for that.  This is only one of many different things we could find in reviewing your code.  In general, write your code like you are submitting it for a code peer review in industry.  \n",
        "- Level of effort is part of our subjective grading.  Oftentimes there is a large disparity between the level of effort between students who are trying learn, and students who are trying to do the minimum possible to check off an assignment requirement.  For example, in cases where we ask for a more open ended investigation, some students put in significant effort and some students do the minimum possible to meet requirements.  In these cases, we may take points off for students who did not put in much effort as compared to students who did put in a lot of effort.  We feel that the students who did a better job deserve a better grade.  We reserve the right to invoke level of effort grading at any time.\n",
        "- Only use spark, spark machine learning, spark data frames, RDD's, and map reduce to solve all problems unless instructed otherwise.\n",
        "- Unless code is provided which reads data files, __you must use the get_training_filename function povided below to read data files.\"  Runtime errors encountered while grading caused by students not using get_training_filename will result in a minimum of half points off for the problem in question.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C3Us59kDLLU",
        "outputId": "e2fe2fd1-faa1-4a38-e8b4-62111ff0485d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%bash\n",
        "\n",
        "# Need to install pyspark\n",
        "# if pyspark is already installed, will print a message indicating pyspark already isntalled\n",
        "pip install pyspark\n",
        "\n",
        "# Download tweets.csv from github\n",
        "# If the tweets.csv file does not exist in the colab environment\n",
        "if [[ ! -f ./tweets.csv ]]; then \n",
        "   # download tweets.csv file from github and save it in this colab environment instance\n",
        "   wget https://raw.githubusercontent.com/wewilli1/ist718_data/master/tweets.csv   \n",
        "fi\n",
        "\n",
        "# vefify tweets.csv exits in the colab env - should not print an error message\n",
        "ls tweets.csv"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (3.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.9)\n",
            "tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZT9J6HFDOnW"
      },
      "source": [
        "# import statements\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjMipt7-DUmO",
        "outputId": "c6e1ac7a-42db-4d66-d0fb-514dcf8c73af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# example code to read the downloaded tweets.csv file on colab\n",
        "tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"tweets.csv\")\n",
        "tweets_df.take(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(target='4', id='1467822272', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='ersle', text='I LOVE @Health4UandPets u guys r the best!! '),\n",
              " Row(target='4', id='1467822273', date='Mon Apr 06 22:22:45 PDT 2009', flag='NO_QUERY', user='becca210', text='im meeting up with one of my besties tonight! Cant wait!!  - GIRL TALK!!'),\n",
              " Row(target='4', id='1467822283', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='Wingman29', text='@DaRealSunisaKim Thanks for the Twitter add, Sunisa! I got to meet you once at a HIN show here in the DC area and you were a sweetheart. '),\n",
              " Row(target='4', id='1467822287', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='katarinka', text='Being sick can be really cheap when it hurts too much to eat real food  Plus, your friends make you soup'),\n",
              " Row(target='4', id='1467822293', date='Mon Apr 06 22:22:46 PDT 2009', flag='NO_QUERY', user='_EmilyYoung', text='@LovesBrooklyn2 he has that effect on everyone ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EMxuKmiDqzj"
      },
      "source": [
        "What problems did you have with colab? Your comments here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1MgILPRDF5U"
      },
      "source": [
        "# Do not delete or change this cell\n",
        "\n",
        "enable_grid = True\n",
        "\n",
        "# grading import statements\n",
        "%matplotlib inline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)\n",
        "import os\n",
        "\n",
        "# Define a function to determine if we are running on data bricks\n",
        "# Return true if running in the data bricks environment, false otherwise\n",
        "def is_databricks():\n",
        "    # get the databricks runtime version\n",
        "    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
        "    \n",
        "    # if running on data bricks\n",
        "    if db_env != None:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Define a function to read the data file.  The full path data file name is constructed\n",
        "# by checking runtime environment variables to determine if the runtime environment is \n",
        "# databricks, or a student's personal computer.  The full path file name is then\n",
        "# constructed based on the runtime env.\n",
        "# \n",
        "# Params\n",
        "#   data_file_name: The base name of the data file to load\n",
        "# \n",
        "# Returns the full path file name based on the runtime env\n",
        "#\n",
        "# Correct Usage Example (pass ONLY the full file name):\n",
        "#   file_name_to_load = get_training_filename(\"sms_spam.csv\") # correct - pass ONLY the full file name  \n",
        "#   \n",
        "# Incorrect Usage Example\n",
        "#   file_name_to_load = get_training_filename(\"/sms_spam.csv\") # incorrect - pass ONLY the full file name\n",
        "#   file_name_to_load = get_training_filename(\"sms_spam.csv/\") # incorrect - pass ONLY the full file name\n",
        "#   file_name_to_load = get_training_filename(\"c:/users/will/data/sms_spam.csv\") incorrect -pass ONLY the full file name\n",
        "def get_training_filename(data_file_name):    \n",
        "    # if running on data bricks\n",
        "    if is_databricks():\n",
        "        # build the full path file name assuming data brick env\n",
        "        full_path_name = \"dbfs:/FileStore/tables/%s\" % data_file_name\n",
        "    # else the data is assumed to be in the same dir as this notebook\n",
        "    else:\n",
        "        # Assume the student is running on their own computer and load the data\n",
        "        # file from the same dir as this notebook\n",
        "        full_path_name = data_file_name\n",
        "    \n",
        "    # return the full path file name to the caller\n",
        "    return full_path_name"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGvKhnMSDF5X"
      },
      "source": [
        "# Sentiment Analysis\n",
        "In this assignment, you will use the tweets.csv file to perform sentiment analysis. The tweets.csv file contains the following columns:\n",
        "- target: the polarity of the tweet (0 = negative, 4 = positive)\n",
        "- ids: The id of the tweet ( 2087)\n",
        "- date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "- flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "- user: the user that tweeted (robotickilldozr)\n",
        "- text: the text of the tweet (Lyx is cool)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EyHCufqDF5Y"
      },
      "source": [
        "# Qustion 1: (10 pts)\n",
        "Read tweets.csv into a spark dataframe named `tweets_df`.  Solutions that do not use `get_training_filename` will be heavily penalized.  Drop all columns except target and text.  Transform the target column such that a negative sentiment is equal to 0 and a positive sentiment is equal to 1.  Determine and print the percentage of positive and negative tweets in the dataframe such that it's easy for the graders to find and interpret your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz1J-vzhDF5Y",
        "outputId": "9bcb809f-ec5b-457b-c96b-3b99d69ad6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# your code here\n",
        "from pyspark.sql import functions as fn\n",
        "\n",
        "#tweets_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(get_training_filename(\"tweets.csv\"))\n",
        "tweets_df = tweets_df.drop('id').drop('date').drop('flag').drop('user')\n",
        "\n",
        "#Transform 4 polarity to 1, negative polarity already correct\n",
        "tweets_df = tweets_df.withColumn('target',fn.translate('target','4','1'))\n",
        "tweets_df = tweets_df.withColumn('target', fn.col('target').cast('long'))\n",
        "\n",
        "\n",
        "#Validate transform\n",
        "tweets_df.select('target').distinct().show()\n",
        "\n",
        "#Need to print percentages\n",
        "percent = tweets_df.groupBy(\"target\").agg(fn.count('*').alias(\"count\"))\n",
        "total = percent.agg(fn.sum('count')).first()[0]\n",
        "percent = percent.withColumn('percentage',fn.col('count')/total)\n",
        "\n",
        "percent.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+\n",
            "|target|\n",
            "+------+\n",
            "|     0|\n",
            "|     1|\n",
            "+------+\n",
            "\n",
            "+------+-----+----------+\n",
            "|target|count|percentage|\n",
            "+------+-----+----------+\n",
            "|     0|50000|       0.5|\n",
            "|     1|50000|       0.5|\n",
            "+------+-----+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6ql2qhwDF5a",
        "outputId": "7fdc06a6-3201-4e15-9c73-b62f8902f17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "# grading cell do not modify\n",
        "tweets_pd = tweets_df.toPandas()\n",
        "display(tweets_pd.head())\n",
        "print(tweets_pd.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im meeting up with one of my besties tonight! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Being sick can be really cheap when it hurts t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target                                               text\n",
              "0       1       I LOVE @Health4UandPets u guys r the best!! \n",
              "1       1  im meeting up with one of my besties tonight! ...\n",
              "2       1  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
              "3       1  Being sick can be really cheap when it hurts t...\n",
              "4       1    @LovesBrooklyn2 he has that effect on everyone "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(100000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhnmGwdGDF5c"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7u-12QHDF5d"
      },
      "source": [
        "# Question 2: (10 pts)\n",
        "Pre-process the data by creating a pipeline named `tweets_pre_proc_pipe`. Your pipeline should tokenize, remove stop words, and do a TF-IDF transformation.  Fit and execute your pipeline, and create a new dataframe named `tweets_pre_proc_df`.  Print the shape of the resulting TF-IDF data such that it's easy for the graders to find and understand as num rows x num words. Based on the shape of the TF-IDF data, would you expect a logistic regression model to overfit?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQUq6sLwDF5d",
        "outputId": "1b9a53e0-d262-4264-e0aa-03677068c83f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# your code here\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from requests import get\n",
        "\n",
        "\n",
        "stop_words = get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()\n",
        "\n",
        "tokenizer = Tokenizer().setInputCol('text').setOutputCol('words')\n",
        "\n",
        "sw_filter = StopWordsRemover()\\\n",
        "  .setStopWords(stop_words)\\\n",
        "  .setCaseSensitive(False)\\\n",
        "  .setInputCol(\"words\")\\\n",
        "  .setOutputCol(\"filtered\")\n",
        "\n",
        "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
        "  .setInputCol(\"filtered\")\\\n",
        "  .setOutputCol(\"tf\")\n",
        "\n",
        "idf = IDF().\\\n",
        "    setInputCol('tf').\\\n",
        "    setOutputCol('tfidf')\n",
        "\n",
        "tweets_pre_proc_pipe = Pipeline(stages=[tokenizer,sw_filter,cv,idf]).fit(tweets_df)\n",
        "\n",
        "tweets_pre_proc_df = tweets_pre_proc_pipe.transform(tweets_df)\n",
        "\n",
        "vocabulary = tweets_pre_proc_pipe.stages[-2].vocabulary\n",
        "print(\"num rows:\", tweets_df.count())\n",
        "print(\"num columns:\", len(vocabulary))\n",
        "\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num rows: 100000\n",
            "num columns: 13693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GsrXa6tDF5f",
        "outputId": "91fd8f07-e909-43cd-e350-9821f7429dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# grading cell do not modify\n",
        "display(tweets_pre_proc_df.toPandas().head())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>words</th>\n",
              "      <th>filtered</th>\n",
              "      <th>tf</th>\n",
              "      <th>tfidf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
              "      <td>[i, love, @health4uandpets, u, guys, r, the, b...</td>\n",
              "      <td>[love, @health4uandpets, u, guys, r, best!!]</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>im meeting up with one of my besties tonight! ...</td>\n",
              "      <td>[im, meeting, up, with, one, of, my, besties, ...</td>\n",
              "      <td>[im, meeting, besties, tonight!, wait!!, , -, ...</td>\n",
              "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
              "      <td>[@darealsunisakim, thanks, for, the, twitter, ...</td>\n",
              "      <td>[@darealsunisakim, thanks, twitter, add,, suni...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Being sick can be really cheap when it hurts t...</td>\n",
              "      <td>[being, sick, can, be, really, cheap, when, it...</td>\n",
              "      <td>[sick, really, cheap, hurts, eat, real, food, ...</td>\n",
              "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
              "      <td>[@lovesbrooklyn2, he, has, that, effect, on, e...</td>\n",
              "      <td>[@lovesbrooklyn2, effect]</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                              tfidf\n",
              "0       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "1       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 3.183...\n",
              "2       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "3       1  ...  (1.1265280578718189, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "4       1  ...  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ZURBmkDF5h"
      },
      "source": [
        "Your explanation here: I do not expect a logistic regression model to overfit because there are a greater number of rows (tweets) in the data set that there are columns (individual words).  The number of tweets are an order of magnitiude greater than the vocabulary and even if splitting the data into a training and testing sets, there should be suffcient number of rows in the training set to avoid overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9wm2Y4lDF5h"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqrfp--ADF5i"
      },
      "source": [
        "# Question 3: (10 pts)\n",
        "Since IDF considers a word's frequency across all documents in a corpus, you can use IDF as a form of inference.  Examine the documentation for the spark ML object that you used to create TF-IDF scores and learn how to extract the IDF scores for words in the corpus.  Create a pandas dataframe containing the 5 most important IDF scores named `most_imp_idf`.  Create another pandas dataframe containing the 5 least important IDF scores named `least_imp_idf`.  Each dataframe shall have 2 columns named `word` and `idf_score`.  Explain in words your interpretation of what the IDF scores mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF9mGO4YDF5i"
      },
      "source": [
        "# your code here\n",
        "idf = tweets_pre_proc_pipe.stages[-1].idf.tolist()\n",
        "vocab = tweets_pre_proc_pipe.stages[-2].vocabulary\n",
        "\n",
        "idfcol = ['word','idf_score']\n",
        "\n",
        "idf_df = spark.createDataFrame(data=zip(vocab,idf),schema = idfcol)\n",
        "\n",
        "most_imp_idf = idf_df.sort(fn.desc('idf_score')).limit(5).toPandas()\n",
        "least_imp_idf = idf_df.sort('idf_score').limit(5).toPandas()\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEwFmAtHDF5k",
        "outputId": "55fd0ed4-3da4-44ca-9101-f7408c497a84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# grading cell do not modify\n",
        "display(most_imp_idf)\n",
        "display(least_imp_idf)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>idf_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thks</td>\n",
              "      <td>9.721176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aku</td>\n",
              "      <td>9.721176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(8)</td>\n",
              "      <td>9.721176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>but..</td>\n",
              "      <td>9.721176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>broke,</td>\n",
              "      <td>9.721176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     word  idf_score\n",
              "0    thks   9.721176\n",
              "1     aku   9.721176\n",
              "2     (8)   9.721176\n",
              "3   but..   9.721176\n",
              "4  broke,   9.721176"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>idf_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>1.126528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>just</td>\n",
              "      <td>2.588812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm</td>\n",
              "      <td>2.645649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>good</td>\n",
              "      <td>3.015945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>like</td>\n",
              "      <td>3.113850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word  idf_score\n",
              "0         1.126528\n",
              "1  just   2.588812\n",
              "2   i'm   2.645649\n",
              "3  good   3.015945\n",
              "4  like   3.113850"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baiQGPevDF5n"
      },
      "source": [
        "Your explanation here: The least important IDF words occur frequently within and across the range of documents so their scores are discounted as they do not provide much meaning because they are so common.  The most important words occur less frequently across the documents and therefore may provide a better indication of sentiment (poisitive or negative) if encountered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-qIIOhDDF5o"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ndzoHoDF5o"
      },
      "source": [
        "# Question 4: (10 pts)\n",
        "Create a new recursive pipeline named `lr_pipe` which starts with `tweets_pre_proc_pipe` and adds a logistic regression model using default hyper parameters.  Fit lr_pipe using `tweets_df`.  Score the model using ROC AUC.  Report the resulting AUC such that it is easy for graders to find and interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcsHp9e_DF5p",
        "outputId": "21b95054-fd9f-45ad-faba-14e4f4356db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# your code here\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "training_df, validation_df, testing_df = tweets_df.randomSplit([0.6, 0.3, 0.1], seed=0)\n",
        "\n",
        "lr = LogisticRegression(labelCol='target',featuresCol='tfidf')\n",
        "\n",
        "lr_pipe = Pipeline(stages = [tweets_pre_proc_pipe,lr]).fit(training_df)\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='target',metricName = 'areaUnderROC')\n",
        "\n",
        "score_lr_pipe = evaluator.evaluate(lr_pipe.transform(validation_df))\n",
        "\n",
        "print('Area under ROC: ', score_lr_pipe)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Area under ROC:  0.7302971442176194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0usF65_DF5r"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDf7Y49JDF5s"
      },
      "source": [
        "# Question 5: (10 pts)\n",
        "Create 2 pandas dataframes named `lr_pipe_df_neg` and `lr_pipe_df_pos`which contain 2 colunms: `word` and `score`.  Load the 2 dataframes with the top 10 words and logistic regression coefficients that contribute the most to negative and positive sentiments respectively. Analyze the 2 dataframes and describe if the words make sense.  Do the words look like they are really negative and positive?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cECeKZE4DF5s"
      },
      "source": [
        "# your code here\n",
        "import pandas as pd\n",
        "vocabulary = lr_pipe.stages[0].stages[-2].vocabulary\n",
        "score = lr_pipe.stages[-1].coefficients.tolist()\n",
        "\n",
        "datacol = ['word','score']\n",
        "\n",
        "coeffs_df = spark.createDataFrame(data=zip(vocabulary,score),schema = datacol)\n",
        "\n",
        "lr_pipe_df_pos = coeffs_df.sort(fn.desc('score')).limit(10).toPandas()\n",
        "lr_pipe_df_neg = coeffs_df.sort('score').limit(10).toPandas()\n",
        "\n",
        "#coeffs_df = pd.DataFrame({'word':vocabulary,'score':score})\n",
        "\n",
        "#lr_pipe_df_pos = coeffs_df.sort_values('score', ascending=False).head(10)\n",
        "#lr_pipe_df_neg = coeffs_df.sort_values('score').head(10)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsfSuHmjDF5u",
        "outputId": "48cc71c0-2a94-4466-b3b3-3ff558b82939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "source": [
        "# grading cell - do not modify\n",
        "display(lr_pipe_df_neg)\n",
        "display(lr_pipe_df_pos)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adopted</td>\n",
              "      <td>-8.641777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>selfish</td>\n",
              "      <td>-8.157059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>depressed</td>\n",
              "      <td>-6.644970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>update:</td>\n",
              "      <td>-6.311959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brutal</td>\n",
              "      <td>-6.265906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@milliemagsaysay</td>\n",
              "      <td>-6.040053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pirates</td>\n",
              "      <td>-5.925209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>why'd</td>\n",
              "      <td>-5.904686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dec</td>\n",
              "      <td>-5.894391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>last!</td>\n",
              "      <td>-5.765711</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               word     score\n",
              "0           adopted -8.641777\n",
              "1           selfish -8.157059\n",
              "2         depressed -6.644970\n",
              "3           update: -6.311959\n",
              "4            brutal -6.265906\n",
              "5  @milliemagsaysay -6.040053\n",
              "6           pirates -5.925209\n",
              "7             why'd -5.904686\n",
              "8               dec -5.894391\n",
              "9             last! -5.765711"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ja</td>\n",
              "      <td>7.734643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lotr</td>\n",
              "      <td>7.166360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pizza?</td>\n",
              "      <td>6.978478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>participating</td>\n",
              "      <td>6.635875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ride!</td>\n",
              "      <td>6.511661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>anyway..</td>\n",
              "      <td>5.679254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>marvelous</td>\n",
              "      <td>5.619924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>demi.</td>\n",
              "      <td>5.526293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ch?</td>\n",
              "      <td>5.113280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>kidding,</td>\n",
              "      <td>5.059666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            word     score\n",
              "0             ja  7.734643\n",
              "1           lotr  7.166360\n",
              "2         pizza?  6.978478\n",
              "3  participating  6.635875\n",
              "4          ride!  6.511661\n",
              "5       anyway..  5.679254\n",
              "6      marvelous  5.619924\n",
              "7          demi.  5.526293\n",
              "8            ch?  5.113280\n",
              "9       kidding,  5.059666"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztdg0Q61DF5x"
      },
      "source": [
        "Your explanation here: Both dataframes contain some words that do not correlate to positive or negative sentiment.  For example in the positive dataframe, it has 'maybe', 'ugh', and 'c.', that do not indicate positivity.  In the negative dataframe, 'chrisptoher', the web url, 'tours', 'lung' don't seem to make sense as negative words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4GIaUCeDF5x"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEE-R3gODF5y"
      },
      "source": [
        "# Question 6a: (5 pts)\n",
        "The goal of this question is to try to improve the score from question 4 using a regularization grid search on a new pipeline named `lr_pipe_1`. lr_pipe_1 is the same as lr_pipe above but we would like you to create a new pipe for grading purposes only.  I'm not sure if it's possible to increase the score or not.  You will be graded on level of effort to increase the score in relation to other students in the class.  All of your grid search code should be inside the `if enable_grid` statement in the cell below.  The enable_grid boolean is set to true in a grading cell above.  If any of the grid search code executes outside of the if statement, you will not get full credit for the question.  We want the ability to turn off the grid search during grading.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOHgwz_1DF5y"
      },
      "source": [
        "enable_grid = True"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NavQTjXMDF50",
        "outputId": "4432ae23-b8a3-48b1-dff9-0ce671bd1cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# your grid search (and only your grid search) code here\n",
        "if enable_grid:\n",
        "    # your grid search code here\n",
        "    from pyspark.ml.tuning import ParamGridBuilder\n",
        "    lr_1 = LogisticRegression(labelCol='target',featuresCol='tfidf')\n",
        "    \n",
        "    grid = ParamGridBuilder().\\\n",
        "    addGrid(lr_1.regParam, [0., 0.01, 0.02]).\\\n",
        "    addGrid(lr_1.elasticNetParam, [0., 0.1, 0.2, 0.3, 0.4]).\\\n",
        "    build()\n",
        "    \n",
        "    lr_pipe_1 = Pipeline(stages = [tweets_pre_proc_pipe,lr_1])\n",
        "    \n",
        "    all_models = []\n",
        "    for j in range(len(grid)):\n",
        "      print(\"Fitting model {}\".format(j+1))\n",
        "      model = lr_pipe_1.fit(training_df, grid[j])\n",
        "      all_models.append(model)\n",
        "    \n",
        "    scores =[]\n",
        "    for m in all_models:\n",
        "      score_lr_pipe_1 = BinaryClassificationEvaluator(labelCol='target',metricName = 'areaUnderROC').evaluate(m.transform(validation_df))\n",
        "      scores.append(score_lr_pipe_1)\n",
        "      \n",
        "    print(grid[scores.index(max(scores))])\n",
        "    pass"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting model 1\n",
            "Fitting model 2\n",
            "Fitting model 3\n",
            "Fitting model 4\n",
            "Fitting model 5\n",
            "Fitting model 6\n",
            "Fitting model 7\n",
            "Fitting model 8\n",
            "Fitting model 9\n",
            "Fitting model 10\n",
            "Fitting model 11\n",
            "Fitting model 12\n",
            "Fitting model 13\n",
            "Fitting model 14\n",
            "Fitting model 15\n",
            "{Param(parent='LogisticRegression_a09ed8e38a1a', name='regParam', doc='regularization parameter (>= 0).'): 0.02, Param(parent='LogisticRegression_a09ed8e38a1a', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrAVQKdWDF52"
      },
      "source": [
        "##### Grading feedback cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQBQggA-DF52"
      },
      "source": [
        "# Question 6b (5 pts)\n",
        "Build a new pipeline named `lr_pipe_2` which uses the optimized model parameters from the grid search in question 6a above (the best model).  Create 2 variables named alpha and lambda and assign to them the best alpha and lambda produced by the grid search by hard coding the values. Fit and transform lr_pipe_2.  Compare AUC scores between lr_pipe_2 with lr_pipe in question 4.  Create a pandas dataframe named `comapre_1_df` which encapsulates the comparison data.  comapre_1_df Shall have 2 columns: `model_name` and `auc_score`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6a_KvWZDF53"
      },
      "source": [
        "# your optimized model code here\n",
        "alpha_par = 0.1\n",
        "lambda_par = 0.02\n",
        "\n",
        "# lr_pipe_2 code here\n",
        "en_lr = LogisticRegression(labelCol='target',featuresCol='tfidf',regParam=lambda_par, elasticNetParam=alpha_par)\n",
        "\n",
        "lr_pipe_2 = Pipeline(stages = [tweets_pre_proc_pipe,en_lr]).fit(training_df)\n",
        "\n",
        "score_pipe_2 = evaluator.evaluate(lr_pipe_2.transform(validation_df))\n",
        "\n",
        "comapre_1_df = pd.DataFrame([['lr_pipe', score_lr_pipe],['lr_pipe_2',score_pipe_2]],columns=['model_name','auc_score'])\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-T5aUbVDF54",
        "outputId": "d3cfe6f0-ef58-4742-bfe0-ee473ec2bf87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# grading cell - do not modify\n",
        "display(comapre_1_df)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lr_pipe</td>\n",
              "      <td>0.730297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lr_pipe_2</td>\n",
              "      <td>0.816809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model_name  auc_score\n",
              "0    lr_pipe   0.730297\n",
              "1  lr_pipe_2   0.816809"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf9D3f7pDF56"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEei3YjXDF56"
      },
      "source": [
        "# Question 7 (10 pts)\n",
        "Perform inference on lr_pipe_2.  Write code to report how many words were eliminated from the best model in question 6b above (if any) as compared to the model in question 4 above.  Make sure your output is easy for the graders to find and interpret."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsmhD_Y8DF57",
        "outputId": "c07c3ebf-71d7-4493-8c36-66e3b32cf76e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# your code here\n",
        "vocabulary_1 = lr_pipe_2.stages[0].stages[-2].vocabulary\n",
        "score_1 = lr_pipe_2.stages[-1].coefficients.toArray().tolist()\n",
        "\n",
        "datacol = ['word','score']\n",
        "\n",
        "coeffs_df_1 = spark.createDataFrame(data=zip(vocabulary_1,score_1),schema = datacol)\n",
        "\n",
        "print('Number of Words Removed from Best Model: ',coeffs_df_1.where(coeffs_df_1['score']==0).count(),'\\nPercent Recdution: ', coeffs_df_1.where(coeffs_df_1['score']==0).count()/coeffs_df_1.count())\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Words Removed from Best Model:  9012 \n",
            "Percent Recdution:  0.6581464982107647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQmOWRekDF58"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqyx-mHLDF59"
      },
      "source": [
        "# Question 8 (10 pts)\n",
        "Perform the same inference analysis that you did in question 5 but name the data frames `lr_pipe_df_neg_1` and `lr_pipe_df_pos_1`.  Compare the word importance results with the results in question 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-yYBjyLDF59"
      },
      "source": [
        "# your code here\n",
        "vocabulary_1 = lr_pipe_2.stages[0].stages[-2].vocabulary\n",
        "score_1 = lr_pipe_2.stages[-1].coefficients.toArray().tolist()\n",
        "\n",
        "datacol = ['word','score']\n",
        "\n",
        "coeffs_df_1 = spark.createDataFrame(data=zip(vocabulary_1,score_1),schema = datacol)\n",
        "\n",
        "lr_pipe_df_pos_1 = coeffs_df_1.sort(fn.desc('score')).limit(10).toPandas()\n",
        "lr_pipe_df_neg_1 = coeffs_df_1.sort('score').limit(10).toPandas()\n",
        "\n",
        "#coeffs_df = pd.DataFrame({'word':vocabulary,'score':score})\n",
        "\n",
        "#lr_pipe_df_pos_1 = coeffs_df.sort_values('score', ascending=False).head(10)\n",
        "#lr_pipe_df_neg_1 = coeffs_df.sort_values('score').head(10)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaTFqx1UDF5_",
        "outputId": "03316e40-a70a-43ca-b991-41ee9b771cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "source": [
        "# grading cell - do not modify\n",
        "display(lr_pipe_df_neg_1)\n",
        "display(lr_pipe_df_pos_1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sad</td>\n",
              "      <td>-0.450782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>miss</td>\n",
              "      <td>-0.330157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>poor</td>\n",
              "      <td>-0.328874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wish</td>\n",
              "      <td>-0.323344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>missing</td>\n",
              "      <td>-0.315183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sick</td>\n",
              "      <td>-0.308480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hurts</td>\n",
              "      <td>-0.305853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sucks</td>\n",
              "      <td>-0.304261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lost</td>\n",
              "      <td>-0.287978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sad.</td>\n",
              "      <td>-0.283056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      word     score\n",
              "0      sad -0.450782\n",
              "1     miss -0.330157\n",
              "2     poor -0.328874\n",
              "3     wish -0.323344\n",
              "4  missing -0.315183\n",
              "5     sick -0.308480\n",
              "6    hurts -0.305853\n",
              "7    sucks -0.304261\n",
              "8     lost -0.287978\n",
              "9     sad. -0.283056"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thanks</td>\n",
              "      <td>0.308825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>guilt</td>\n",
              "      <td>0.283446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thank</td>\n",
              "      <td>0.281859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>welcome</td>\n",
              "      <td>0.272772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>owners</td>\n",
              "      <td>0.253157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>wiff</td>\n",
              "      <td>0.247450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>good</td>\n",
              "      <td>0.237222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>kiddos</td>\n",
              "      <td>0.234237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>peaceful</td>\n",
              "      <td>0.227550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@jonthanjay</td>\n",
              "      <td>0.224960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          word     score\n",
              "0       thanks  0.308825\n",
              "1        guilt  0.283446\n",
              "2        thank  0.281859\n",
              "3      welcome  0.272772\n",
              "4       owners  0.253157\n",
              "5         wiff  0.247450\n",
              "6         good  0.237222\n",
              "7       kiddos  0.234237\n",
              "8     peaceful  0.227550\n",
              "9  @jonthanjay  0.224960"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmG3zMADF6A"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GquZfziADF6B"
      },
      "source": [
        "Your explanation here:By removing the unneeded words from the model, the negative and postive words inference makes much more sense.  Now instead of having words that do not seem to relate as in Q5, you are left with words that intuitively relate to being positive or negative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HUbjdC4DF6B"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvr9xC9DF6B"
      },
      "source": [
        "# Question 9 (10 pts)\n",
        "Create a receiver operating characteristic (ROC) plot for the best model in question 6.  Briefly describe in words the high level steps needed to build a ROC curve as outlined in lecture.  Convince me you understand the high level steps needed to make a ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmRxGA8-DF6C",
        "outputId": "369a0be0-2cd7-449f-c3d4-1cd8a560f3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# your code here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lr_pipe_2.stages[-1].summary.roc.select('FPR').collect(),\n",
        "         lr_pipe_2.stages[-1].summary.roc.select('TPR').collect())\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqoHo4wKDF6D"
      },
      "source": [
        "Your explanation here:To construct an ROC curve you iterate hundreds to thousands of times over the possible probability thresholds that a model predicts an outcome and calculate the true positive rate and false positive rate using a given threshold.  In this case predicting, the probability of a tweet being positive. You use each probability theshold to create a confusion matrix to calculate the TPR and FPR (e.g. model predicts this tweet as .6 probability of being positive, threshold is .5 so tweet is marked positive.  Then compare it to the true condition to fill in confusion matrix).  Then all points are plotted using TPR and FPR as y and x coordinates for each threshold value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywJfQc1tDF6E"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7GwjkVdDF6E"
      },
      "source": [
        "# Question 10 (10 pts)\n",
        "Learn about [precision/recall](https://en.wikipedia.org/wiki/Precision_and_recall) curves. Using the logistic regression summary object contained in the linear regression object within lr_pipe_2, create a precision recall plot. Similar to the `roc` object which is available in the logistic regression summary, there is a `pr` object which can be used to help create a precision / recall curve.  Note that the precision recall curve is built using the same high level methodology as the ROC curve, but using different metrics calculated from the confusion matrix.  If you understand how a ROC curve is built, you understand how a precision / recall curve is built.  Compare and contrast the differences between precision / recall and ROC curves.  What axis is common and what axis is different between the 2 curves?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjO8JllcDF6E",
        "outputId": "5e15c4c5-d7cd-4312-dc4d-df92c76921b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# your code here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lr_pipe_2.stages[-1].summary.pr.select('Recall').collect(),\n",
        "         lr_pipe_2.stages[-1].summary.pr.select('Precision').collect())\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1bn/8c+TeU4gCUMSIIwCImMcQMF5rtjBtmod22rb297O9ra3w+10b3tvf7W9tbZVW621rbNV9GqtWkVBREAmAYXImDCFEAIhZH5+f5wDjWmEA+ScfZLzfb9e58UZdvZ+Fuj5Zq+191rm7oiISOJKCroAEREJloJARCTBKQhERBKcgkBEJMEpCEREEpyCQEQkwSkIpNcws4+Z2d8i2O43ZvbtWNQUC2a20czOCz//rpn9MeiapG9REEiPCH9ZHTCzBjPbYWa/N7OcnjyGu//J3S+IYLtPu/sPevLYB5mZm9n+cDurzexWM0uOxrGOhZnlmdnPzWxzuMZ3wq+Lgq5N4peCQHrSZe6eA0wFKoBvdd3AzFJiXlXPmxRu55nAR4GPB1wPAGaWBrwAnAhcBOQB04Fa4JRj2F9f+LeSCCgIpMe5ezXwDDABDv0W/VkzWwesC7/3PjNbZmZ7zOxVM5t48OfNbIiZPWZmNWZWa2a/DL9/g5nNCz83M/uZme00s71mttLMDh7v92b2w077u8nMKs1st5nNMbOSTp+5mX3azNaFa7ndzCzCdlYC84HJnfZ3LO0aaWZ/D7+3y8z+ZGYFR/0XD9cBQ4EPuPtqd+9w953u/gN3f7pTe0d1qunQ35WZnWVmVWb2b2a2HbjHzNaY2fs6bZ8Srn9q+PVp4XbuMbPlZnbWMdQtAVMQSI8zsyHAJcDSTm+/HzgVGG9mU4C7gU8BhcAdwBwzSw93szwFbALKgVLggW4OcwEwCxgD5AMfIfSbb9dazgF+FP58cHi/Xff3PuBkYGJ4uwsjbOdYYCZQGX59rO2ycI0lwDhgCPDdSGro4jzgr+7ecAw/e9AgoD8wDLgZuB+4qtPnFwK73P0NMysF/g/4Yfhnvgo8ambFx3F8CYCCQHrS42a2B5gHzAX+q9NnP3L33e5+gNAXzB3uvtDd2939XqAZOI1QF0YJcIu773f3Jnef182xWoFcYCxg7r7G3bd1s93HgLvd/Q13bwa+AUw3s/JO2/zY3fe4+2bgRTr9hv8e3jCz/cAa4CXgV+H3j6ld7l7p7s+5e7O71wC3Eup2OlqFQHd/B0ejA/iPcC0HgD8Ds80sK/z51YTCAeAa4Gl3fzp89vEcsJjQLwHSiygIpCe9390L3H2Yu/9L+IvkoC2dng8DvhLuTtgTDo8hhL4ohwCb3L3tcAdy978DvwRuB3aa2Z1mltfNpiWEfgs/+HMNhM4cSjtts73T80YgB8DMVoUHXBvMbGanbaaGt/koobOc7ONpl5kNNLMHwoPPe4E/AscyuFtL6KzneNS4e9PBF+HurzXAZeEwmE0oHCDU3g93ae8ZPVCDxJiCQGKl8zS3W4D/DIfGwUeWu98f/mxoJAOV7v4Ld58GjCfURXRLN5ttJfSFBYCZZRP6zbk6gv2f6O454ccrXT5zd38IWAB85zjb9V+E/n5Ocvc8Qr9pRzRO0cXzwIXhNr6XRiCr0+tBXT7vbjrig91DlwOrw+EAoTbd16W92e7+42OoXQKkIJAg3AV82sxODQ/6ZpvZpWaWC7xOqHvjx+H3M8zs9K47MLOTwz+fCuwHmgh1a3R1P3CjmU02s3RCX7oL3X1jD7Xlx8BNZjboONqVCzQA9eF+9+4CLRL3EfpyftTMxppZkpkVmtm/m9nB7pplwNVmlmxmFxFZF9QDhMZkPsM/zgYgdOZymZldGN5fRnjAuewY65eAKAgk5tx9MXAToa6dOkKDrTeEP2sHLgNGAZuBKkJdMF3lEfrirSPU9VML/KSbYz0PfBt4lNAX8Ujgyh5sy0rgZUJ9/8faru8R6m6qJzT4+tgx1tJMaMD4LeA5YC+hACoCFoY3+0K4jj2Exk8ej2C/2wid+cwAHuz0/hZCZwn/DtQQCqFb0PdKr2NamEZEJLEpuUVEEpyCQEQkwSkIREQSnIJARCTB9bpJpYqKiry8vDzoMkREepUlS5bscvdup//odUFQXl7O4sWLgy5DRKRXMbNN7/VZ1LqGzOxuC80M+eZ7fG5m9gsLzQq54uBshiIiElvRHCP4PaE50d/LxcDo8ONm4NdRrEVERN5D1ILA3V8Gdh9mk8uBP4TnbHkNKDAzTVYlIhJjQV41VMq7Z6Ss4t0zQh5iZjeb2WIzW1xTUxOT4kREEkWvuHzU3e909wp3rygu1poXIiI9KcggqCY0R/tBZUQwNbCIiPSsIINgDnBd+Oqh04D691hhSkREoihq9xGY2f3AWUCRmVUB/wGkArj7b4CnCS1pV0losYwbo1ULQGNLGw3N/7zoVWu7U7e/hd3hR+3+Fppa25lUVsC0Yf3ITEuOZlkiIoGLWhC4+1VH+NyBz0br+F3dt2ATP3rmraP6mdRkY/KQAqaPKGTSkAIAWto6aGnvoLmtg9b2DiaWFnBSWX40ShYRiYled2fxsTpjdBE/TJ/wT++nJBkFWWkU5qTRPzuNwuw0kpOMJZvqWLC+ltfW7+aXL1bScZhlG6YOLeCG04dz8YRBpCb3ivF3EZFDet3CNBUVFR7rKSb2NbWybmcDKUlGanISaSlJpCUnkZRk/G3Vdu59dSMbaxsZmJfONacO49QRhQzOz2BAXjrpKepaEpHgmdkSd6/o9jMFwfHr6HDmrq3hnlc38vLad9/nUJSTxuD8TEYUZzNrdDGzxhRTnJseUKUikqgOFwQJ0zUUTUlJxtljB3D22AFU1TWyvmY/2+ub2FbfxPa9B9hW38T8ylqeWLYVgJNK8znrhGLOOqGYSWUFpKg7SUQCpDOCGOnocFZv28tLb+/kpbdreGNzHR0OeRkpnDG66NDZQklBZtClikgfpK6hOFTf2Mq8yl3MXbuTl9fuYvveJgBGDchhxshCTh1eyKkj+lOUo24kETl+CoI45+6s29nAy2treHndLhZv3E1jSzsQCobpIwr56MlDmFCqy1RF5NgoCHqZ1vYO3qyu57X1u1m4oZbXN4SCYeboIj595khmjCzEzIIuU0R6EQVBL1d/oJU/L9zM3fM3ULOvmZNK87n61KEMyE0nKy2F7PTkQ38OyM0gOUkhISLvpiDoI5pa2/nL0mrufHk9G3bt73ab9JQkRg3I4YSBuYwZlMsJA3M5YVAug/MzdBYhksAUBH1Me4ezsXY/+5vb2N/cTmNLG/tb2tnX1Mqm2kbe2r6Ptdv3HRqAhtDVSRNK85lQms+JJXmcVJpPeWE2STp7EEkIuo+gj0lOMkYW5xxxu/rGVtbu3Mdb2/exZtte3qyu5/fzN9LS3gFAbnoKk4YUMHVoAVOG9mPK0AIKstKiXb6IxBkFQR+Wn5XKyeX9Obm8/6H3Wts7WLejgTer61letYelm/e8ay6lIf0zKSvIorRfJqUFmZT2y2Ro/yzGDc4jPzM1oJaISDQpCBJManIS40vyGF+Sx0dODq0LtL+5jRVV9byxuY63tu+juq6Reet2sWNfE517DssLsziprICJpfmcWJrHqAE5FOeka+xBpJdTEAjZ6SlMH1nI9JGF73q/pa2D7fVNbKjdz5vV9aysqueNTXU8uXzroW3yM1MZNSCHUcU5oT/Dj5KCTF29JNJLaLBYjtquhmbWbNtL5c4GKnc2sG5nA+/sbKB2f8uhbdJTkhhelM2oATmMHZTLtGH9mTykQAv9iAREg8XSo4py0pk5upiZo4vf9X7d/hYqa0Kh8E5NA+/U7GdFVT1PrQitQJqSZJxYmk/FsH5UDOvHhNJ8yvplqmtJJGA6I5Co29PYwhub61i8MfRYVrWHlrbQlUv5malMKM1jQkk+J5bmM6EkT5e1ikSBzggkUAVZaZwzdiDnjB0IQHNbO6u37mXVoUc997y68VA45KSnML4kFA6ThuQza3Qx/bJ1WatItOiMQOLCoctat9bzZnXosXrbXppaO0gyqCjvz/njBnLe+IEML8oOulyRXkd3Fkuv1Nbewaqte3lhzQ6eW7OTNdv2AjCiKJuJZfmMHpjLmIG5jBmYw5B+WepOEjkMBYH0CVV1jbywZicvvb2Tt7bvY1v9P6bQyEgNzbE0rDCbIf2yKOuXGX6Enmek6molSWwKAumT9ja1sm5HA+t27GPtjgbW7dzHlt2NVO85QGv7P/67Tk02xg/OOzSNxtSh/XS1kiQcBYEklI4OZ+e+ZrbUNVJV18jaHQ28samOFVX1HGgNLfgzvCib2ZNKuHxyCSMimLdJpLdTEIgQGnN4a/s+lmyq49lV21mwvhZ3mFiWz+xJJcwaU8zoATk6U5A+SUEg0o3t9U08tWIrTyzbysrqegD6Z6dxcnm/Q2tGjxuUp0Fo6RMUBCJHsLm2kdc21LJw/W5e31jLlt0HACjMTmPGqCJmjirijNFFlBRkBlypyLHRDWUiRzC0MIuhhVl8pCI0I+vWPQdY8E4t8yp3Ma9y16GJ9k4YmMv540P3M0wszdfZgvQJOiMQOQJ3Z+2OBl5ZV8Pza3awaGMd7R3OgNx0zh03kAtOHMiMkYWkp+gSVYlf6hoS6UF1+1t4ae1Onlu9g7lv17C/pZ3stGTOGjuAC8YP5OyxA8jL0CI+El8UBCJR0tzWzquVtfxt9XaeW72DXQ0tpKckcdmkEq6bPoyJZQVBlygCBBgEZnYR8L9AMvBbd/9xl8+HAXcDxcBu4Bp3rzrcPhUEEq/aO5xlW+p47I1q/rK0msaWdiYNKeDa04bxvomDdXezBCqQIDCzZGAtcD5QBSwCrnL31Z22eRh4yt3vNbNzgBvd/drD7VdBIL3B3qZW/vJGNX9YsJF3avaTm57CaSMLOWNUEaePKmJkcbbuV5CYCuqqoVOASndfHy7iAeByYHWnbcYDXw4/fxF4PIr1iMRMXkYq188o57rpw1jwTi1PrtjKK+t28dzqHQAMzs9g1uhizh8/kDNGF+lsQQIVzSAoBbZ0el0FnNplm+XABwl1H30AyDWzQnevjWJdIjFjZswYVcSMUUVA6H6F0CWpNTy9chsPLt5CRmoSM8OhcO7YARTmpAdctSSaoO8j+CrwSzO7AXgZqAbau25kZjcDNwMMHTo0lvWJ9KihhVlcXTiUq08dSktbBws31PLc6h2HHslJxpljivnQ1DLOHTdAZwoSE9EcI5gOfNfdLwy//gaAu//oPbbPAd5y97LD7VdjBNIXuTurtu7lqRXb+MvSKnbsbSYvI4XLJpVwxbQyJg8p0JiCHJegBotTCA0Wn0voN/1FwNXuvqrTNkXAbnfvMLP/BNrd/TuH26+CQPq69g5nfuUuHn2jimdXbaeptYNRA3K4YloZH5xSyoC8jKBLlF4oyMtHLwF+Tujy0bvd/T/N7PvAYnefY2ZXAD8CnFDX0Gfdvflw+1QQSCLZ29TK0yu28fCSKpZsqiPJ4OwTBnDdjHJmjirSFBcSMd1QJtIHrK9p4JElVTy0uIpdDc2MKM7m+unlfGhaGTnpQQ/3SbxTEIj0IS1tHTy9chv3vLqR5Vv2kJOewgemlPL+KaVMHaqxBOmegkCkj1q6uY57X93IM29up7mtgyH9M7l8Uinvn1LCqAG5QZcncURBINLH7Wtq5dlVO3hiWTXzK3fR4TBlaAGfPGMEF544kJTkpKBLlIApCEQSyM69TcxZvpX7XtvEptpGyvplcuPpw/noyUM0lpDAFAQiCai9w3lu9Q5++8p6Fm+qIzcjhSumlXHtacMYUZwTdHkSYwoCkQS3dHMdd8/fyDMrt9HW4cwcXcT108s5Z+wAXYKaIBQEIgLAzn1NPPD6Fv68cDPb9zYxfnAeX7lgDOeMHaCrjfo4BYGIvEtbewdPrtjKz59fx6baRiYPKeBL549h1ugiBUIfpSAQkW61tnfw6JIqfvHCOrbWNzGiKJurTx3KFdPKKMhKC7o86UEKAhE5rOa2dp5euY0/vraZJZvqSE9J4n0TS7h+hpbb7CsUBCISsdVb9/KnhZt4fGk1+1vaOaW8P5+cOZzzxg3UwHIvpiAQkaO2r6mVBxdt4Z75G6nec4DhRdl86fwxXDZxsMYReqHDBYFuNxSRbuVmpPLJmSOYe8tZ3HbVFLLSkvn8/Uu56Q9L2LG3KejypAcpCETksFKSk7hsUglzPncG37xkHK+sq+H8W+fy8OIt9LYeBemegkBEIpKcZNw0awR//eIsxg7K45ZHVnDDPYvYVLs/6NLkOCkIROSoDC/K5oGbT+N7s09k0cbdnHfrXL735Crq9rcEXZocIwWBiBy1pCTj+hnlvPTVs7hiWhn3vrqRWT95kTvmvkNTa3vQ5clRUhCIyDEbkJfBjz44kb9+cRYVw/rxo2fe4tyfzuWJZdV0dGj8oLdQEIjIcRszMJd7bjyFP33yVPIzU/nCA8u4/Pb5LHinNujSJAIKAhHpMaePKuKpfz2DWz8yidqGZq666zU+ee8iKnfuC7o0OQwFgYj0qKQk44NTy/j7V8/iaxedwML1u7nw56/wzb+spGZfc9DlSTd0Z7GIRFVtQzO3/b2SP762ifSUJD515kg+OXM4WWlaLS2WdGexiASmMCed784+kee+fCYzRxdz63NrOfv/vcRDi7bQrgHluKAgEJGYGF6UzW+uncYjn55OSUEmX3t0BZf+4hXmrq0JurSEpyAQkZiqKO/PY5+Zwe1XT6WxpZ3r736da3+3kNVb9wZdWsJSEIhIzJkZl04czPNfPpPvvG88K6vrufS2V/jqw8s1oBwABYGIBCYtJYmPnzGcubeczc0zR/DEsmrO+elL3Ldgo8YPYkhBICKBy89M5RuXjOOvX5zFpLICvv3EKt5/+3yWbdkTdGkJQUEgInFjZHEO933iFG67ago79zXxgV/N5xuPrWRPoya0iyYFgYjEFTPjskklvPCVs/jE6cN5aPEWzvnpXB5avEXzF0WJgkBE4lJOegrfet94nvrXMxhRlM3XHlnBh+9YoKuLokBBICJxbdzgPB761HR+csVENuzaz2W/nMcPnlrN/ua2oEvrM6IaBGZ2kZm9bWaVZvb1bj4famYvmtlSM1thZpdEsx4R6Z2SkowPVwzh7185k4+ePITfzdvABT97mRff3hl0aX1C1ILAzJKB24GLgfHAVWY2vstm3wIecvcpwJXAr6JVj4j0fgVZafzXB07i4U9PJzMtmRvvWcQXH1jKgRYthnM8onlGcApQ6e7r3b0FeAC4vMs2DuSFn+cDW6NYj4j0ESeX9+f/Pn8GXzh3NE8s38r197zOvqbWoMvqtaIZBKXAlk6vq8LvdfZd4BozqwKeBv61ux2Z2c1mttjMFtfUaF4SEYH0lGS+dP4Y/vfKKbyxqY6P/XYhu7Vu8jEJerD4KuD37l4GXALcZ2b/VJO73+nuFe5eUVxcHPMiRSR+zZ5Uwp3XTePt7fv46B0L2F7fFHRJvU40g6AaGNLpdVn4vc4+ATwE4O4LgAygKIo1iUgfdM7Ygfz+xlPYuucAl/1yHks21QVdUq8SzSBYBIw2s+FmlkZoMHhOl202A+cCmNk4QkGgvh8ROWrTRxby6L/MIDM1mSvvXMADr28OuqReI6IgMLPTzew5M1trZuvNbIOZrT/cz7h7G/A54FlgDaGrg1aZ2ffNbHZ4s68AN5nZcuB+4AbvbUumiUjcGDsojzmfO53TRhTy9cdW8q3HV9LS1hF0WXEvoqUqzewt4EvAEuDQdVruXhu90rqnpSpF5Eja2jv4ybNvc8fL65k6tIA7r6ugKCc96LIC1RNLVda7+zPuvtPdaw8+erBGEZEek5KcxDcuGcftV09l9ba9XPHrV9lUuz/osuJWpEHwopn9xMymm9nUg4+oViYicpwunTiYP990GvUHWvnQr19lRZWmte5OpF1DL3bztrv7OT1f0uGpa0hEjtY7NQ1c97vX2b2/hduumsJ54wcGXVLMHXfXkLuf3c0j5iEgInIsRhbn8JfPzmD0wBxuvm8xf1iwMeiS4kqkVw3lm9mtB+/uNbOfmll+tIsTEekpA3IzeODm0zhn7EC+88QqfvDUaq1vEBbpGMHdwD7gI+HHXuCeaBUlIhINWWkp3HHtNG6YUc7v5m3ga4+u0NrIQEqE24109w91ev09M1sWjYJERKIpOcn4j8vG0y8rjZ89v5am1nZ+9tHJpCYHPeNOcCINggNmdoa7z4PQDWbAgeiVJSISPWbGF84bTUZqEj965i2aWjv45dVTyEhNDrq0QEQaBJ8B7g2PCxiwG7ghWkWJiMTCp84cSVZaMt9+YhWfvHcxd143jay0SL8W+46IWuzuy4BJZpYXfq1FQ0WkT7h2ejmZaSl87ZHlXPu717nj2mkJdxfyYYPAzK5x9z+a2Ze7vA+Au98axdpERGLiimll5KQn88UHlzH7tnnceV0FE0oT58LII42OZIf/zH2Ph4hIn3DRhME88ukZAFzxm1d5ZV3iTIQc0Z3F8UR3FotINO1qaOZjdy2kpqGZZ74wk4F5GUGX1COO+85iM/sfM8szs1Qze8HMaszsmp4tU0QkeEU56dz+sSkcaGnn8/cvTYj7DCK9cPaC8ADx+4CNwCjglmgVJSISpFEDcvnB+yewcMNu/vf5tUGXE3WRBsHBQeVLgYfdvT5K9YiIxIUrppVxxbQybnuxkpfe3hl0OVEVaRA8FV6cZhrwgpkVA1ohWkT6tB9cPoETBubyxQeXUb2n795DG+nso18HZgAV7t4K7Acuj2ZhIiJBy0xL5jfXTKO1rYNvPLaS3nZxTaQOGwRmdk74zw8CZwGXh59fRCgYRET6tPKibL520VheXlvDE8u2Bl1OVBzpzuIzgb8Dl3XzmQOP9XhFIiJx5prThvHEsmq+9+Qqzhhd1OfuPNZ9BCIiEVi7Yx+X3TaPacP68YePn0JKL5uttCfuI/gvMyvo9Lqfmf2wpwoUEYl3Ywbm8p8fOIlX36nlv//6VtDl9KhII+1idz+06rO71wGXRKckEZH4dMW0Mq6bPoy7XtnAk8v7znhBpEGQbGaHOsXMLBPoW51kIiIR+Nal45k6tICvP7qCyp0NQZfTIyINgj8Run/gE2b2CeA54N7olSUiEp/SUpK4/WNTSU9N5jN/XMKBlvagSzpukd5H8N/AD4Fx4ccP3P1/olmYiEi8Gpyfyc8/Opl1Oxv4n2d7/3jB0SzFswZoc/fnzSzLzHLdfV+0ChMRiWezxhRz/fRh3DN/IxeMH8T0kYVBl3TMIr1q6CbgEeCO8FulwOPRKkpEpDf4t4vHUl6YxTf/spLW9o6gyzlmkY4RfBY4HdgL4O7rgAHRKkpEpDfISkvhm5eOZ/2u/Ty4aEvQ5RyzSIOg2d1bDr4wsxRCdxaLiCS088YNoGJYP37+/DoaW9qCLueYRBoEc83s34FMMzsfeBh4MnpliYj0DmbGNy4Zy66GZu59dVPQ5RyTSIPg34AaYCXwKeBp4FvRKkpEpDeZNqw/Z44p5o6X32FfU2vQ5Ry1IwaBmSUDa9z9Lnf/sLtfEX5+xK4hM7vIzN42s0oz+3o3n//MzJaFH2vNbE93+xERiXdfPn8MexpbuWf+xqBLOWpHDAJ3bwfeNrOhR7PjcIDcDlwMjAeuMrPxXfb9JXef7O6TgdvQbKYi0ktNGlLAeeMGctcr66lv7F1nBZF2DfUDVoUXrp9z8HGEnzkFqHT39eGB5gc4/GI2VwH3R1iPiEjc+fL5Y9jX1MZv560PupSjEukNZd8+hn2XAp2vp6oCTu1uQzMbBgwntPZBd5/fDNwMMHToUZ2YiIjEzPiSPC49aTB3z9vAtdOHMSA3I+iSInKkFcoyzOyLwIeBscB8d5978NGDdVwJPBLuhvon7n6nu1e4e0VxcXEPHlZEpGd99cITaG13fvx075l64khdQ/cCFYSuFroY+OlR7LsaGNLpdVn4ve5cibqFRKQPGF6UzU2zhvPY0moWbdwddDkROVIQjHf3a9z9DuAKYOZR7HsRMNrMhptZGqEv+38aVzCzsYTGIBYcxb5FROLWZ88exeD8DL7/5Go6OuL/3tsjBcGhoW93P6pb5sLbfw54ltCEdQ+5+yoz+76Zze606ZXAA5Fcjioi0htkpaXwbxeNZWV1PY8tfa+OkPhx2DWLzawd2H/wJZAJNIafu7vnRb3CLrRmsYj0Bh0dzvt/NZ+9B1p58atnYWaB1nPMaxa7e7K754Ufue6e0ul5zENARKS3SEoyrptezsbaRhZtrAu6nMOK9D4CERE5SpecNIjstGQeXhzfM5MqCEREoiQrLYXZk0uYs3wru/e3HPkHAqIgEBGJohtPH05zWwd/ei1+ZyZVEIiIRNGYgbmcOaaYP7y2iea2+FzoXkEgIhJlN80cQc2+Zp5YtjXoUrqlIBARibLTRxUybnAed728nni8ZUpBICISZWbGjTPKWbezgeVV9UGX808UBCIiMXDhhEGkJSfx5PL46x5SEIiIxEB+ZiqzxhTz1IqtcTf/kIJARCRGZk8uYcfeZl5bXxt0Ke+iIBARiZELxg8kNyOFh5dUBV3KuygIRERiJCM1mdmTSnh65Tb2NsXPusYKAhGRGPrg1DKa2zr426odQZdyiIJARCSGpg4toKxfJnPi6OohBYGISAyZGbMnlTC/che1Dc1BlwMoCEREYu6ySSW0dzjPvLk96FIABYGISMyNHZTLqAE5cdM9pCAQEYkxM+P9k0t4fcNuNtc2Bl2OgkBEJAgfnFqGGTzyRvD3FCgIREQCUFKQyekji3h8aXXgM5IqCEREAjJ7UgmbdzeysjrYGUkVBCIiAbnwxEGkJhv/t3JboHUoCEREApKflUrFsP7Mfbsm0DoUBCIiATrzhGLe2r6P7fVNgdWgIBARCdCs0cUAzK/cFVgNCgIRkQCNHZRLv6xUFgS4RoGCQEQkQElJxvSRhcxbtyuwy0gVBCIiATv7hAFs39vEqq17Azm+gkBEJGDnjB2AGbywZmcgx1cQiIgErDAnnZNK8wMbMI5qEPi6H80AAApSSURBVJjZRWb2tplVmtnX32Obj5jZajNbZWZ/jmY9IiLx6vRRRbyxuY79zW0xP3bUgsDMkoHbgYuB8cBVZja+yzajgW8Ap7v7icAXo1WPiEg8O31kEW0dzusbdsf82NE8IzgFqHT39e7eAjwAXN5lm5uA2929DsDdg+kgExEJWEV5P9JSkgLpHopmEJQCWzq9rgq/19kYYIyZzTez18zsou52ZGY3m9liM1tcUxPsrdgiItGQkZrMtKH9mP9O7O8nCHqwOAUYDZwFXAXcZWYFXTdy9zvdvcLdK4qLi2NcoohIbJxc3o+3t++N+ThBNIOgGhjS6XVZ+L3OqoA57t7q7huAtYSCQUQk4UwZ1o8OhxVVsZ2WOppBsAgYbWbDzSwNuBKY02WbxwmdDWBmRYS6itZHsSYRkbg1dUg/zGDhhth2D0UtCNy9Dfgc8CywBnjI3VeZ2ffNbHZ4s2eBWjNbDbwI3OLuwU24ISISoPysVCaW5jNvXWwHjFOiuXN3fxp4ust73+n03IEvhx8iIglv5uhifj33HeoPtJKfmRqTYwY9WCwiIp3MGlNMe4ezIIZXDykIRETiyJShBWSnJcf0fgIFgYhIHElNTmLK0H4s2VQXs2MqCERE4szUYf14K4b3EygIRETizOQh+XQ4vFkdm/sJFAQiInFmYllogoWVCgIRkcRUlJNObkYKW3Y3xuR4CgIRkTg0OD+DrfVNMTmWgkBEJA6VFmSyuVZnBCIiCeuksgLW7dwXkyuHFAQiInFoytCCmM1EqiAQEYlDk8JXDq2o2hP1YykIRETiUP/sNMr6ZcbkElIFgYhInBpZnMOGXfujfhwFgYhInCovzGJTbSOhGfujR0EgIhKnhhZm09Dcxu79LVE9joJARCRODS/KAoh695CCQEQkTp0wKA+ANdv3RfU4CgIRkThVkp9BfmYqq7fujepxFAQiInHKzDixJI9VW6N7CamCQEQkjo0aEP1LSBUEIiJxrCgnnX1NbTS3tUftGAoCEZE4VlKQCcDWPdGbklpBICISx4YVhi4h3Vgbve4hBYGISBw7eEawPYqL1CgIRETiWHFOOmawTUEgIpKY0lKSGJSXQVUU1y9WEIiIxLlhhVkaIxARSWQji3Oo3NkQtf0rCERE4lx5YTZ7m9qoP9Aalf0rCERE4tw/7iU4EJX9KwhEROJccW46ALsamqOy/6gGgZldZGZvm1mlmX29m89vMLMaM1sWfnwymvWIiPRGBVmpAFHrGkqJyl4BM0sGbgfOB6qARWY2x91Xd9n0QXf/XLTqEBHp7dJTQr+zN7d2RGX/0TwjOAWodPf17t4CPABcHsXjiYj0SWnhIGhp731BUAps6fS6KvxeVx8ysxVm9oiZDeluR2Z2s5ktNrPFNTU10ahVRCRuZaencPGEQZSGB417WtCDxU8C5e4+EXgOuLe7jdz9TnevcPeK4uLimBYoIhK0vIxUfn3NNGaNic73XzSDoBro/Bt+Wfi9Q9y91t0PDoP/FpgWxXpERKQb0QyCRcBoMxtuZmnAlcCczhuY2eBOL2cDa6JYj4iIdCNqVw25e5uZfQ54FkgG7nb3VWb2fWCxu88BPm9ms4E2YDdwQ7TqERGR7pm7B13DUamoqPDFixcHXYaISK9iZkvcvaK7z4IeLBYRkYApCEREEpyCQEQkwSkIREQSXK8bLDazGmDTMf54EbCrB8vpDdTmxKA2J4bjafMwd+/2jrReFwTHw8wWv9eoeV+lNicGtTkxRKvN6hoSEUlwCgIRkQSXaEFwZ9AFBEBtTgxqc2KISpsTaoxARET+WaKdEYiISBcKAhGRBNcng8DMLjKzt82s0sy+3s3n6Wb2YPjzhWZWHvsqe1YEbf6yma0Orwb3gpkNC6LOnnSkNnfa7kNm5mbW6y81jKTNZvaR8L/1KjP7c6xr7GkR/Lc91MxeNLOl4f++Lwmizp5iZneb2U4ze/M9Pjcz+0X472OFmU097oO6e596EJry+h1gBJAGLAfGd9nmX4DfhJ9fCTwYdN0xaPPZQFb4+WcSoc3h7XKBl4HXgIqg647Bv/NoYCnQL/x6QNB1x6DNdwKfCT8fD2wMuu7jbPMsYCrw5nt8fgnwDGDAacDC4z1mXzwjOAWodPf17t4CPABc3mWby/nHspiPAOeamcWwxp52xDa7+4vu3hh++RqhFeN6s0j+nQF+APw30BTL4qIkkjbfBNzu7nUA7r4zxjX2tEja7EBe+Hk+sDWG9fU4d3+Z0Pos7+Vy4A8e8hpQ0GWRr6PWF4OgFNjS6XVV+L1ut3H3NqAeKIxJddERSZs7+wSh3yh6syO2OXzKPMTd/y+WhUVRJP/OY4AxZjbfzF4zs4tiVl10RNLm7wLXmFkV8DTwr7EpLTBH+//7EUVthTKJT2Z2DVABnBl0LdFkZknArSTeqncphLqHziJ01veymZ3k7nsCrSq6rgJ+7+4/NbPpwH1mNsHdO4IurLfoi2cE1cCQTq/Lwu91u42ZpRA6nayNSXXREUmbMbPzgG8Cs929OUa1RcuR2pwLTABeMrONhPpS5/TyAeNI/p2rgDnu3uruG4C1hIKht4qkzZ8AHgJw9wVABqHJ2fqqiP5/Pxp9MQgWAaPNbLiZpREaDJ7TZZs5wPXh51cAf/fwKEwvdcQ2m9kU4A5CIdDb+43hCG1293p3L3L3cncvJzQuMtvde/M6p5H8t/04obMBzKyIUFfR+lgW2cMiafNm4FwAMxtHKAhqYlplbM0BrgtfPXQaUO/u245nh32ua8jd28zsc8CzhK44uNvdV5nZ94HF7j4H+B2h08dKQoMyVwZX8fGLsM0/AXKAh8Pj4pvdfXZgRR+nCNvcp0TY5meBC8xsNdAO3OLuvfZsN8I2fwW4y8y+RGjg+Ibe/Iudmd1PKMyLwuMe/wGkArj7bwiNg1wCVAKNwI3Hfcxe/PclIiI9oC92DYmIyFFQEIiIJDgFgYhIglMQiIgkOAWBiEiCUxCIdMPM2s1smZm9aWZPmllBD+9/Y/g6f8ysoSf3LXK0FAQi3Tvg7pPdfQKhe00+G3RBItGiIBA5sgWEJ/Uys5Fm9lczW2Jmr5jZ2PD7A83sL2a2PPyYEX7/8fC2q8zs5gDbIPKe+tydxSI9ycySCU1f8LvwW3cCn3b3dWZ2KvAr4BzgF8Bcd/9A+Gdywtt/3N13m1kmsMjMHu3Nd/pK36QgEOleppktI3QmsAZ4zsxygBn8Y5oOgPTwn+cA1wG4ezuhqc0BPm9mHwg/H0JoAjgFgcQVBYFI9w64+2QzyyI0z81ngd8De9x9ciQ7MLOzgPOA6e7eaGYvEZoQTSSuaIxA5DDCq7p9ntDEZo3ABjP7MBxaO3ZSeNMXCC0Bipklm1k+oenN68IhMJbQVNgicUdBIHIE7r4UWEFoAZSPAZ8ws+XAKv6xbOIXgLPNbCWwhNDauX8FUsxsDfBjQlNhi8QdzT4qIpLgdEYgIpLgFAQiIglOQSAikuAUBCIiCU5BICKS4BQEIiIJTkEgIpLg/j+FpAwIAE2C8QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zv4geq5DF6G"
      },
      "source": [
        "Your explanation here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUL8VKNpDF6G"
      },
      "source": [
        "##### Grading Feedback Cell"
      ]
    }
  ]
}